# HealthierYou Bariatric Clinic RAG Assistant

An AI-powered knowledge assistant that provides accurate, citation-backed answers about HealthierYou Bariatric Clinic services, pricing, onboarding, and policies using Retrieval-Augmented Generation (RAG).

[![Live Demo](https://img.shields.io/badge/ğŸ¤—%20Hugging%20Face-Spaces-blue)](https://huggingface.co/spaces/xanderKariuki/healthieryou-rag)
[![Python 3.13+](https://img.shields.io/badge/python-3.13+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## project Overview
HealthierYou RAG is an AI system that allows users to ask natural language questions over a curated knowledge base (KB) related to a bariatric and weight-loss clinic.

Instead of relying purely on a language modelâ€™s memory, this system:
1. Retrieves relevant documents from a vector database.
2. Augments the prompt with those documents.
3. Generates grounded, explainable answers using an LLM.

This ensures:
1. Higher factual accuracy
2. Reduced hallucinations
3. Domain-specific intelligence

## âœ¨ Features

- ğŸ” **Semantic Search** - Understands intent, not just keywords
- ğŸ“š **Source Citations** - Every answer includes references [1], [2]
- ğŸ¯ **Confidence Gating** - Refuses to answer when information isn't available
- ğŸ”„ **LLM Reranking** - Intelligently selects most relevant content
- ğŸ› **Debug Mode** - Transparent retrieval and ranking insights

## ğŸš€ Quick Start

```bash
# Clone repository
git clone https://github.com/AlexKarari/ask-my-docs.git
cd ask-my-docs

# Create a virtual environment
python -m venv .venv
source .venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Set up environment variables by creating a .env file
OPENAI_API_KEY=your_api_key_here

# Build vector database
python ingest.py

# Run the app
python app.py
```

Open http://127.0.0.1:7860 in your browser.

## ğŸ—ï¸ How It Works

```
User Question
      â†“
1. Retrieve top-k candidates (vector search)
2. Confidence gate (refuse if similarity too low)
3. Rerank with LLM (select best 3 chunks)
4. Generate grounded answer with citations
      â†“
Answer + Sources + Debug Info
```

## ğŸ“ Project Structure

```
healthieryou-rag/
â”œâ”€â”€ app.py                # Gradio UI
â”œâ”€â”€ ingest.py             # Document ingestion
â”œâ”€â”€ requirements.txt      # Dependencies
â”œâ”€â”€ core/                 # RAG pipeline modules
â”‚   â”œâ”€â”€ config.py         # Configuration settings
â”‚   â”œâ”€â”€ chunking.py       # Markdown-aware chunking
â”‚   â”œâ”€â”€ embeddings.py     # OpenAI embeddings API
â”‚   â”œâ”€â”€ store.py          # ChromaDB interface
â”‚   â”œâ”€â”€ retriever.py      # Vector similarity search
â”‚   â”œâ”€â”€ reranker.py       # LLM-based reranking
â”‚   â”œâ”€â”€ generator.py      # Grounded answer generation
â”‚   â””â”€â”€ rag_pipeline.py   # End-to-end orchestration
â””â”€â”€ kb/                   # Knowledge base (Markdown)
    â”œâ”€â”€ 01_about.md
    â”œâ”€â”€ 02_pricing.md
    â”œâ”€â”€ 03_onboarding.md
    â”œâ”€â”€ 04_data_privacy.md
    â””â”€â”€ 05_support_faq.md
```

## âš™ï¸ Configuration

Key settings in `core/config.py`:

```python
CONFIG = {
    "retrieve_k": 12,              # Initial candidates from vector search
    "max_best_distance": 0.5,      # Confidence threshold (lower = stricter)
    "keep_n_after_rerank": 3,      # Final chunks sent to LLM
    "temperature": 0.0             # Generation randomness (0 = deterministic)
}
```

## ğŸ› ï¸ Tech Stack

| Component | Technology |
|-----------|------------|
| **UI** | Gradio 6.5 |
| **Embeddings** | OpenAI text-embedding-3-small |
| **Vector Database** | ChromaDB |
| **LLM** | OpenAI GPT-4o-mini |
| **Deployment** | Hugging Face Spaces |

## ğŸ“ Adding Documents

1. Add Markdown files to `kb/` folder (use numbering: `06_new_topic.md`)
2. Run `python ingest.py` to rebuild vector database
3. Restart the app

## ğŸŒ Deployment on Hugging Face Spaces

1. Create a new Space at https://huggingface.co/spaces
2. Select SDK: **Gradio**
3. Add `OPENAI_API_KEY` in **Settings â†’ Repository secrets**
4. Push your code - the Space auto-builds and deploys

## ğŸ› Troubleshooting

**"I don't know based on the current knowledge base"**
- The question isn't covered in your KB documents
- Add relevant content to `kb/` and re-run `python ingest.py`

**App not starting locally**
- Verify `OPENAI_API_KEY` is set in `.env`
- Run `python ingest.py` to create vector database first

## ğŸ“š Resources

- [Live Demo](https://huggingface.co/spaces/xanderKariuki/healthieryou-rag)
- [RAG Explained](https://docs.anthropic.com/en/docs/build-with-claude/rag)
- [OpenAI Embeddings Guide](https://platform.openai.com/docs/guides/embeddings)

## ğŸ“„ License

MIT License - see LICENSE file for details

---

Built with â¤ï¸ | ğŸ˜ª | ğŸ˜“ to demonstrate production-ready RAG with semantic chunking, confidence gating, and grounded generation.

**Questions / comments / suggestions?** Open an issue or contact: karari.alexander@gmail.com